{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f72f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in c:\\users\\priyanka\\appdata\\roaming\\python\\python39\\site-packages (1.9.2)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "\n",
    "import sys \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "from wordcloud import WordCloud    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e4129a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/PRIYANKA/Fake news detection/code/fake_or_real_news.csv')\n",
    "data = data.drop(data.columns[[0, 1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbc457a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text label\n",
      "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE\n",
      "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE\n",
      "2     U.S. Secretary of State John F. Kerry said Mon...  REAL\n",
      "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE\n",
      "4     It's primary day in New York and front-runners...  REAL\n",
      "...                                                 ...   ...\n",
      "6330  The State Department told the Republican Natio...  REAL\n",
      "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE\n",
      "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE\n",
      "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL\n",
      "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL\n",
      "\n",
      "[6335 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5896173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9256a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\priyanka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords corpus if you haven't already\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14af4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the stopwords for English\n",
    "stop = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "333055fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'data' is your DataFrame and 'text' is the column containing text data\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d30f4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['label'] == 'FAKE', 'label',] = 0\n",
    "data.loc[data['label'] == 'REAL', 'label',] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257d0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "Y = data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9e67640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Daniel Greenfield, Shillman Journalism Fellow ...\n",
      "1       Google Pinterest Digg Linkedin Reddit Stumbleu...\n",
      "2       U.S. Secretary State John F. Kerry said Monday...\n",
      "3       — Kaydee King (@KaydeeKing) November 9, 2016 l...\n",
      "4       primary day New York front-runners Hillary Cli...\n",
      "                              ...                        \n",
      "6330    State Department told Republican National Comm...\n",
      "6331    ‘P’ PBS Stand ‘Plutocratic’ ‘Pentagon’ Posted ...\n",
      "6332    Anti-Trump Protesters Tools Oligarchy Reform ...\n",
      "6333    ADDIS ABABA, Ethiopia —President Obama convene...\n",
      "6334    Jeb Bush Suddenly Attacking Trump. Here's Matt...\n",
      "Name: text, Length: 6335, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67eefef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "6330    1\n",
      "6331    0\n",
      "6332    0\n",
      "6333    1\n",
      "6334    1\n",
      "Name: label, Length: 6335, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e9070dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m all_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([text \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m real_data\u001b[38;5;241m.\u001b[39mtext])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Generate the word cloud\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Generate the word cloud with a TrueType font specified\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m110\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollocations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_to_your_font.ttf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Display the word cloud\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\wordcloud\\wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\wordcloud\\wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    620\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\wordcloud\\wordcloud.py:503\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    500\u001b[0m tried_other_orientation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;66;03m# try to find a position\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[43mImageFont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruetype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfont_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;66;03m# transpose font optionally\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[0;32m    506\u001b[0m         font, orientation\u001b[38;5;241m=\u001b[39morientation)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFont.py:844\u001b[0m, in \u001b[0;36mtruetype\u001b[1;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfreetype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isPath(font):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFont.py:841\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[1;34m(font)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfreetype\u001b[39m(font):\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFreeTypeFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFont.py:193\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[1;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    191\u001b[0m                 load_from_bytes(f)\n\u001b[0;32m    192\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfont\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_engine\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     load_from_bytes(font)\n",
      "\u001b[1;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "fake_data = data[data[\"label\"] == 0]\n",
    "all_words = ' '.join([text for text in fake_data.text])\n",
    "\n",
    "wordcloud = WordCloud(width= 800, height= 500,\n",
    "                          max_font_size = 110,\n",
    "                          collocations = False).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81009b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already imported necessary libraries including matplotlib.pyplot and WordCloud\n",
    "\n",
    "# Filter the DataFrame to get the text data with label equal to 1\n",
    "real_data = data[data[\"label\"] == 1]\n",
    "\n",
    "# Join all the text data into a single string\n",
    "all_words = ' '.join([text for text in real_data.text])\n",
    "\n",
    "# Generate the word cloud\n",
    "# Generate the word cloud with a TrueType font specified\n",
    "wordcloud = WordCloud(width=800, height=500, max_font_size=110, collocations=False, font_path='path_to_your_font.ttf').generate(all_words)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = data[data[\"label\"] == 1]\n",
    "all_words = ' '.join([text for text in real_data.text])\n",
    "\n",
    "wordcloud = WordCloud(width= 800, height= 500,\n",
    "                          max_font_size = 110,\n",
    "                          collocations = False).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774066c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf21fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the text data to feature vectors that can be used as input to the Logistic regression\n",
    "\n",
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "\n",
    "# convert Y_train and Y_test values as integers\n",
    "\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fb17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ad529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)\n",
    "print('Accuracy on training data : ', accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)\n",
    "print('Accuracy on test data : ', accuracy_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_features)\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "sns.heatmap(cm,annot = True,cmap = 'Reds') # plot CM for train data\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = cm.tolist()\n",
    "pielist = []\n",
    "for i in list:\n",
    "    for j in i:\n",
    "        pielist.append(j)\n",
    "print(pielist)\n",
    "df = pd.DataFrame(pielist)\n",
    "print(plt.pie(df[0], labels=['True Negative', 'False Positive', 'False Negative', 'True Positive'], radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85932004",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mail = [\"Passengers in trouble as C Rly cancels Nagpur-Pune Garib Rath\"]\n",
    "\n",
    "# convert text to feature vectors\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Real news')\n",
    "\n",
    "else:\n",
    "  print('Fake news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f745ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
